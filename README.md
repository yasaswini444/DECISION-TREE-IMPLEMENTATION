# -DECISION-TREE-IMPLEMENTATION
*COMPANY*: CODTECH IT SOLUTIONS
*NAME*: REDDI YASASWINI
*INTERN ID*: CT04DF886
*DOMAIN* : MACHINE LEARNING
*DURATION* : 4 WEEKS
*MENTOR* : NEELA SANTOSH
*PLATFROM* : VS CODE
*REQUIREMENTS* : PANDAS,SCIKIT-LEARN
A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It works by splitting the data into branches based on feature values, ultimately leading to a decision or prediction at the leaf nodes.
What Is a Decision Tree?
Imagine making decisions by asking a series of yes/no or if/else questions — that’s how a decision tree works.
How It Works:
Root Node – The top of the tree where splitting starts.

Internal Nodes – Where decisions are made (e.g., "Is feature X ≤ value?").

Leaf Nodes – Final decision/prediction outcomes.

Branches – Paths taken based on decision conditions.
Key Concepts:
Term	         Meaning
Entropy/Gini	  :Measures of impurity used to find the best splits.
Information Gain :	How much uncertainty is reduced after a split.
Overfitting    	 :Trees that are too deep may memorize the training data.
Pruning	         :Technique to reduce tree size and prevent overfitting.
Advantages:
Easy to understand and interpret.
Handles both numerical and categorical data.
Requires little data preparation (no normalization needed).
Disadvantages:
Prone to overfitting (especially deep trees).
Small changes in data can lead to different trees.
Less accurate than ensemble methods like Random Forests.
*OUTPUT*
![Image](https://github.com/user-attachments/assets/6bdb9102-4bf8-4230-bf18-c4998b7fa89e)
